{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/wiki-tr.parquet\")\n",
    "df = df.sample(25000,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wikipedia_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'https?://(?:www\\.)?[a-zA-Z0-9-]+\\.[a-zA-Z]{2,6}(?:/[^\\s]*)?', '', text)\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    text = re.sub(r'\\{\\{.*?\\}\\}', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'<ref.*?>.*?</ref>', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\[\\[.*?\\|', '', text)\n",
    "    text = re.sub(r'\\[\\[|\\]\\]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s.]', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_text = df.copy()\n",
    "df_cleaned_text[\"text\"] = df.text.apply(clean_wikipedia_text)\n",
    "df_cleaned_text.to_parquet(\"../data/cleaned_data_25000.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/cleaned_data_25000.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(text):\n",
    "    return re.sub(r'[^a-zA-ZçğıöşüÇĞİÖŞÜ\\s]', '', text)\n",
    "\n",
    "def tokenizer(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def convert_lower_case(tokens):\n",
    "    return [token.lower() for token in tokens]\n",
    "\n",
    "def clear_stop_words(tokens):\n",
    "    with open(\"../lib/turkce-stop-words.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "        stopwords = f.read().splitlines()\n",
    "    return [token for token in tokens if token not in stopwords]\n",
    "\n",
    "def create_ngrams_file(tokens,out_path,n=2):\n",
    "    ngramss = list(ngrams(tokens, n))\n",
    "    ngram_freq = Counter(ngramss)\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        for ngram, freq in ngram_freq.items():\n",
    "            ngram_str = ' '.join(ngram)\n",
    "            f.write(f\"{ngram_str}\\t{freq}\\n\")\n",
    "\n",
    "def write_cleaned(text):\n",
    "    out = clean_str(text)\n",
    "    out = tokenizer(text)\n",
    "    out = convert_lower_case(text)\n",
    "    out = clear_stop_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ''.join(df['text'])\n",
    "tokens = tokenizer(all_text)\n",
    "tokens = convert_lower_case(tokens)\n",
    "tokens = clear_stop_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ngrams_file(tokens,\"../lib/unigrams.txt\",n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ngrams_file(tokens,\"../lib/bigrams.txt\",n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ngrams_file(tokens,\"../lib/trigrams.txt\",n=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MlEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
